advanced regression
===

# why do we fit?

- interpreting results

## who cares? what works?

- log posterior is a convex loss in data plus a regularizer
- [generic form](http://web.cse.ohio-state.edu/mlss09/mlss09_talks/5.june-FRI/jordan.pdf) in terms of [convex](http://en.wikipedia.org/wiki/Convex_function#Definition) functions; see also [paper](http://arxiv.org/pdf/math/0510521.pdf)
52a59,69

# optimization

- gradient descent
- stochastic gradient descent
- connect with parallelism

# time permitting: BIC

- derivation
- innoculation
