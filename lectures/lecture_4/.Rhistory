removeParentheses <- function(x){
gsub("\\(.*\\)$", "", x)
}
mrOptions <- strsplit("Excel, R, Stata, D3, Gephi, ggplot2, lattice, SQL, git / Github, SPSS, shell (terminal / command line), regular expressions (grep), Rstudio, JSON, Python, Sweave/knitr, Processing (language), C/C++, Leaflet, CartoDB, GeoJSON, node/npm, go language, ruby, LaTeX, Heroku, Make, Pandas, Julia, non-git version control, XML, Web: html css js, vagrant/virtualbox, amazon web services, dropbox, google drive (formerly docs), OpenRefine (formerly Google refine), Pair programming", ", ")[[1]]
#mrOptions <- removeParentheses(mrOptions)
expandSelections <- function(selected, options){
selected <- removeParentheses(selected)
sapply(options, grepl, x=selected, fixed=TRUE) # returns a logical if ture
}
gridLevels <- c("None", "A little", "Confident", "Expert")
makeOrderedFactor <- function(col, levels){
return (factor(col, levels=levels, labels=levels, ordered=TRUE))
}
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
#plot(colSums(mrLogical))
#barplot(colSums(mrLogical))
#qplot(colSums(mrLogical))
plotdf <- data.frame(
count=colSums(mrLogical),
item=factor(colnames(mrLogical)))
plotdf$item <- with(plotdf, reorder(item, count))
ggplot(plotdf, aes(y=count, x=item)) + geom_bar(stat="identity") + coord_flip()
require(RCurl)
require(ggplot2)
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
df <- read.csv(textConnection(con), stringsAsFactors=FALSE, check.names=FALSE)
str(df)
removeParentheses <- function(x){
gsub("\\(.*\\)$", "", x)
}
mrOptions <- strsplit("Excel, R, Stata, D3, Gephi, ggplot2, lattice, SQL, git / Github, SPSS, shell (terminal / command line), regular expressions (grep), Rstudio, JSON, Python, Sweave/knitr, Processing (language), C/C++, Leaflet, CartoDB, GeoJSON, node/npm, go language, ruby, LaTeX, Heroku, Make, Pandas, Julia, non-git version control, XML, Web: html css js, vagrant/virtualbox, amazon web services, dropbox, google drive (formerly docs), OpenRefine (formerly Google refine), Pair programming", ", ")[[1]]
mrOptions <- removeParentheses(mrOptions)
expandSelections <- function(selected, options){
selected <- removeParentheses(selected)
sapply(options, grepl, x=selected, fixed=TRUE) # returns a logical if ture
}
gridLevels <- c("None", "A little", "Confident", "Expert")
makeOrderedFactor <- function(col, levels){
return (factor(col, levels=levels, labels=levels, ordered=TRUE))
}
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
#plot(colSums(mrLogical))
#barplot(colSums(mrLogical))
#qplot(colSums(mrLogical))
plotdf <- data.frame(
count=colSums(mrLogical),
item=factor(colnames(mrLogical)))
plotdf$item <- with(plotdf, reorder(item, count))
ggplot(plotdf, aes(y=count, x=item)) + geom_bar(stat="identity") + coord_flip()
df
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
View(mrLogical)
require(RCurl)
require(ggplot2)
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
df <- read.csv(textConnection(con), stringsAsFactors=FALSE, check.names=FALSE)
str(df)
removeParentheses <- function(x){
gsub("\\(.*\\)$", "", x)
}
mrOptions <- strsplit("Excel, R, Stata, D3, Gephi, ggplot2, lattice, SQL, git / Github, SPSS, shell (terminal / command line), regular expressions (grep), Rstudio, JSON, Python, Sweave/knitr, Processing (language), C/C++, Leaflet, CartoDB, GeoJSON, node/npm, go language, ruby, LaTeX, Heroku, Make, Pandas, Julia, non-git version control, XML, Web: html css js, vagrant/virtualbox, amazon web services, dropbox, google drive (formerly docs), openrefine (formerly Google refine), Pair programming", ", ")[[1]]
mrOptions <- removeParentheses(mrOptions)
expandSelections <- function(selected, options){
selected <- removeParentheses(selected)
sapply(options, grepl, x=selected, fixed=TRUE) # returns a logical if ture
}
gridLevels <- c("None", "A little", "Confident", "Expert")
makeOrderedFactor <- function(col, levels){
return (factor(col, levels=levels, labels=levels, ordered=TRUE))
}
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
#plot(colSums(mrLogical))
#barplot(colSums(mrLogical))
#qplot(colSums(mrLogical))
plotdf <- data.frame(
count=colSums(mrLogical),
item=factor(colnames(mrLogical)))
plotdf$item <- with(plotdf, reorder(item, count))
ggplot(plotdf, aes(y=count, x=item)) + geom_bar(stat="identity") + coord_flip()
require(RCurl)
require(ggplot2)
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
df <- read.csv(textConnection(con), stringsAsFactors=FALSE, check.names=FALSE)
#str(df)
removeParentheses <- function(x){
gsub("\\(.*\\)$", "", x)
}
mrOptions <- strsplit("Excel, R, Stata, D3, Gephi, ggplot2, lattice, SQL, git / Github, SPSS, shell (terminal / command line), regular expressions (grep), Rstudio, JSON, Python, Sweave/knitr, Processing (language), C/C++, Leaflet, CartoDB, GeoJSON, node/npm, go language, ruby, LaTeX, Heroku, Make, Pandas, Julia, non-git version control, XML, Web: html css js, vagrant/virtualbox, amazon web services, dropbox, google drive (formerly docs), openrefine (formerly Google refine), Pair programming", ", ")[[1]]
mrOptions <- removeParentheses(mrOptions)
expandSelections <- function(selected, options){
selected <- removeParentheses(selected)
sapply(options, grepl, x=selected, fixed=TRUE) # returns a logical if ture
}
gridLevels <- c("None", "A little", "Confident", "Expert")
makeOrderedFactor <- function(col, levels){
return (factor(col, levels=levels, labels=levels, ordered=TRUE))
}
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
#plot(colSums(mrLogical))
#barplot(colSums(mrLogical))
#qplot(colSums(mrLogical))
plotdf <- data.frame(
count=colSums(mrLogical),
item=factor(colnames(mrLogical)))
plotdf$item <- with(plotdf, reorder(item, count))
ggplot(plotdf, aes(y=count, x=item)) + geom_bar(stat="identity") + coord_flip()
require(RCurl)
require(ggplot2)
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
df <- read.csv(textConnection(con), stringsAsFactors=FALSE, check.names=FALSE)
#str(df)
removeParentheses <- function(x){
gsub("\\(.*\\)$", "", x)
}
mrOptions <- strsplit("Excel, R, Stata, D3, Gephi, ggplot2, lattice, SQL, git / Github, SPSS, shell (terminal / command line), regular expressions (grep), Rstudio, JSON, Python, Sweave/knitr, Processing (language), C/C++, Leaflet, CartoDB, GeoJSON, node/npm, go language, ruby, LaTeX, Heroku, Make, Pandas, Julia, non-git version control, XML, Web: html css js, vagrant/virtualbox, amazon web services, dropbox, google drive (formerly docs), OpenRefine (formerly Google refine), Pair programming", ", ")[[1]]
mrOptions <- removeParentheses(mrOptions)
expandSelections <- function(selected, options){
selected <- removeParentheses(selected)
sapply(options, grepl, x=selected, fixed=TRUE) # returns a logical if ture
}
gridLevels <- c("None", "A little", "Confident", "Expert")
makeOrderedFactor <- function(col, levels){
return (factor(col, levels=levels, labels=levels, ordered=TRUE))
}
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
#plot(colSums(mrLogical))
#barplot(colSums(mrLogical))
#qplot(colSums(mrLogical))
plotdf <- data.frame(
count=colSums(mrLogical),
item=factor(colnames(mrLogical)))
plotdf$item <- with(plotdf, reorder(item, count))
ggplot(plotdf, aes(y=count, x=item)) + geom_bar(stat="identity") + coord_flip()
require(RCurl)
require(ggplot2)
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
df <- read.csv(textConnection(con), stringsAsFactors=FALSE, check.names=FALSE)
#str(df)
removeParentheses <- function(x){
gsub("\\(.*\\)$", "", x)
}
mrOptions <- strsplit("Excel, R, Stata, D3, Gephi, ggplot2, lattice, SQL, git / Github, SPSS, shell (terminal / command line), regular expressions (grep), Rstudio, JSON, Python, Sweave/knitr, Processing (language), C/C++, Leaflet, CartoDB, GeoJSON, node/npm, go language, ruby, LaTeX, Heroku, Make, Pandas, Julia, non-git version control, XML, Web: html css js, vagrant/virtualbox, amazon web services, dropbox, google drive (formerly docs), OpenRefine (formerly Google refine), Pair programming", ", ")[[1]]
mrOptions <- removeParentheses(mrOptions)
expandSelections <- function(selected, options){
selected <- removeParentheses(selected)
sapply(options, grepl, x=selected, fixed=TRUE) # returns a logical if ture
}
gridLevels <- c("None", "A little", "Confident", "Expert")
makeOrderedFactor <- function(col, levels){
return (factor(col, levels=levels, labels=levels, ordered=TRUE))
}
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
#plot(colSums(mrLogical))
#barplot(colSums(mrLogical))
#qplot(colSums(mrLogical))
plotdf <- data.frame(
count=colSums(mrLogical),
item=factor(colnames(mrLogical)))
plotdf$item <- with(plotdf, reorder(item, count))
ggplot(plotdf, aes(y=count, x=item)) + geom_bar(stat="identity") + coord_flip()
#con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
require(RCurl)
require(ggplot2)
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
df <- read.csv(textConnection(con), stringsAsFactors=FALSE, check.names=FALSE)
#str(df)
removeParentheses <- function(x){
gsub("\\(.*\\)$", "", x)
}
mrOptions <- strsplit("Excel, R, Stata, D3, Gephi, ggplot2, lattice, SQL, git / Github, SPSS, shell (terminal / command line), regular expressions (grep), Rstudio, JSON, Python, Sweave/knitr, Processing (language), C/C++, Leaflet, CartoDB, GeoJSON, node/npm, go language, ruby, LaTeX, Heroku, Make, Pandas, Julia, non-git version control, XML, Web: html css js, vagrant/virtualbox, amazon web services, dropbox, google drive (formerly docs), OpenRefine (formerly Google refine), Pair programming", ", ")[[1]]
mrOptions <- removeParentheses(mrOptions)
expandSelections <- function(selected, options){
selected <- removeParentheses(selected)
sapply(options, grepl, x=selected, fixed=TRUE) # returns a logical if ture
}
gridLevels <- c("None", "A little", "Confident", "Expert")
makeOrderedFactor <- function(col, levels){
return (factor(col, levels=levels, labels=levels, ordered=TRUE))
}
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
#plot(colSums(mrLogical))
#barplot(colSums(mrLogical))
#qplot(colSums(mrLogical))
plotdf <- data.frame(
count=colSums(mrLogical),
item=factor(colnames(mrLogical)))
plotdf$item <- with(plotdf, reorder(item, count))
ggplot(plotdf, aes(y=count, x=item)) + geom_bar(stat="identity") + coord_flip()
fix(gridLevels)
detach("package:RCurl", unload=TRUE)
library("RCurl", lib.loc="/Users/stump/Library/R/3.0/library")
library(RCurl)
library(ggplot2)
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
fix(expandSelections)
df <- read.csv(textConnection(con), stringsAsFactors=FALSE, check.names=FALSE)
library(RCurl)
library(ggplot2)
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
df <- read.csv(textConnection(con), stringsAsFactors=FALSE, check.names=FALSE)
#str(df)
removeParentheses <- function(x){
gsub("\\(.*\\)$", "", x)
}
mrOptions <- strsplit("Excel, R, Stata, D3, Gephi, ggplot2, lattice, SQL, git / Github, SPSS, shell (terminal / command line), regular expressions (grep), Rstudio, JSON, Python, Sweave/knitr, Processing (language), C/C++, Leaflet, CartoDB, GeoJSON, node/npm, go language, ruby, LaTeX, Heroku, Make, Pandas, Julia, non-git version control, XML, Web: html css js, vagrant/virtualbox, amazon web services, dropbox, google drive (formerly docs), OpenRefine (formerly Google refine), Pair programming", ", ")[[1]]
mrOptions <- removeParentheses(mrOptions)
expandSelections <- function(selected, options){
selected <- removeParentheses(selected)
sapply(options, grepl, x=selected, fixed=TRUE) # returns a logical if ture
}
gridLevels <- c("None", "A little", "Confident", "Expert")
makeOrderedFactor <- function(col, levels){
return (factor(col, levels=levels, labels=levels, ordered=TRUE))
}
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
#plot(colSums(mrLogical))
#barplot(colSums(mrLogical))
#qplot(colSums(mrLogical))
plotdf <- data.frame(
count=colSums(mrLogical),
item=factor(colnames(mrLogical)))
plotdf$item <- with(plotdf, reorder(item, count))
ggplot(plotdf, aes(y=count, x=item)) + geom_bar(stat="identity") + coord_flip()
library(RCurl)
library(ggplot2)
con <- getURL("https://docs.google.com/spreadsheets/d/19a0O6C14zButypjcnWictvKWeyPjPjQdrps-UXzPDf8/export?format=csv")
df <- read.csv(textConnection(con), stringsAsFactors=FALSE, check.names=FALSE)
#str(df)
removeParentheses <- function(x){
gsub("\\(.*\\)$", "", x)
}
mrOptions <- strsplit("Excel, R, Stata, D3, Gephi, ggplot2, lattice, SQL, git / Github, SPSS, shell (terminal / command line), regular expressions (grep), Rstudio, JSON, Python, Sweave/knitr, Processing (language), C/C++, Leaflet, CartoDB, GeoJSON, node/npm, go language, ruby, LaTeX, Heroku, Make, Pandas, Julia, non-git version control, XML, Web: html css js, vagrant/virtualbox, amazon web services, dropbox, google drive (formerly docs), OpenRefine (formerly Google refine), Pair programming", ", ")[[1]]
mrOptions <- removeParentheses(mrOptions)
expandSelections <- function(selected, options){
selected <- removeParentheses(selected)
sapply(options, grepl, x=selected, fixed=TRUE) # returns a logical if ture
}
#gridLevels <- c("None", "A little", "Confident", "Expert")
makeOrderedFactor <- function(col, levels){
return (factor(col, levels=levels, labels=levels, ordered=TRUE))
}
mrLogical <- t(sapply(df[['Baseline experience']], expandSelections, options=mrOptions))
#plot(colSums(mrLogical))
#barplot(colSums(mrLogical))
#qplot(colSums(mrLogical))
plotdf <- data.frame(
count=colSums(mrLogical),
item=factor(colnames(mrLogical)))
plotdf$item <- with(plotdf, reorder(item, count))
ggplot(plotdf, aes(y=count, x=item)) + geom_bar(stat="identity") + coord_flip()
fix(expandSelections)
View(pos)
devtools::install_github(c("adletaw/captioner/captioner", "hadley/bookdown"))
# installing/loading the latest installr package:
install.packages("installr"); require(installr) #load / install+load installr
updateR()
devtools::install_github(c("adletaw/captioner/captioner", "hadley/bookdown"))
install.packages("glmnet", verbose=TRUE, dependencies = TRUE, repos="http://cran.us.r-project.org")
install.packages("ggplot2", verbose=TRUE, dependencies = TRUE, repos="http://cran.us.r-project.org")
install.packages("dplyr", verbose=TRUE, dependencies = TRUE, repos="http://cran.us.r-project.org")
install.packages("ggplot2", verbose=TRUE, dependencies = TRUE, repos="http://cran.us.r-project.org")
install.packages("scales", verbose=TRUE, dependencies = TRUE, repos="http://cran.us.r-project.org")
install.packages("reshape", verbose=TRUE, dependencies = TRUE, repos="http://cran.us.r-project.org")
# script to play with regression.
# borrows from flow of chapter 6 of 'machine learning for hackers'
# clear memory
rm(list=ls())
# let's make us some fake data.
## x
x <- seq(-10, 10, by = 0.01)
## y
y <- x ^ 2 + rnorm(length(x), 0, 5)
# plot it
plot(x,y)
# make it fancy
library(ggplot2)
ggplot(data.frame(X = x, Y = y), aes(x = X, y = Y)) +
geom_point() +
# even fancier, please
ggplot(data.frame(X = x, Y = y), aes(x = X, y = Y)) +
geom_point() +
geom_smooth(se = FALSE)
# define a variable for x^2
x.2 <- x ^ 2
# plot y against it.
plot(x.2,y)
# make it fancier
ggplot(data.frame(XSquared = x.2, Y = y), aes(x = XSquared, y = Y)) +
geom_point()
# now makeit fancy with a smooth cuve
ggplot(data.frame(XSquared = x.2, Y = y), aes(x = XSquared, y = Y)) +
geom_point()
geom_smooth(se = FALSE)
# now make it fancy with a smooth curve learned from lm
ggplot(data.frame(XSquared = x.2, Y = y), aes(x = XSquared, y = Y)) +
geom_point() +
geom_smooth(method = 'lm', se = FALSE)
# NOW LET'S START US SOME MODELING:
# fit to x^1
lm.out<-lm(y~x)
lm.out$coefficients
# what there are 2 coeffs? yes there's constant by default.
# we can make it explicit too:
lm.out<-lm(y~1+x)
lm.out$coefficients
# what of polynom?
lm.out<-lm(y~x.2)
lm.out$coefficients
# whoa, what of both?
lm.out<-lm(y~x.2+x)
lm.out$coefficients
# convince yourself this makes sense.
## MODEL SIN CURVE
x <- seq(0, 1, by = 0.01)
y <- sin(2 * pi * x) + rnorm(length(x), 0, 0.1)
# let's use data frames to make the whole of the polynomial:
df <- data.frame(X = x, Y = y)
df <- transform(df, X2 = X ^ 2)
df <- transform(df, X3 = X ^ 3)
df <- transform(df, X4 = X ^ 4)
df <- transform(df, X5 = X ^ 5)
df <- transform(df, X6 = X ^ 6)
df <- transform(df, X7 = X ^ 7)
df <- transform(df, X8 = X ^ 8)
df <- transform(df, X9 = X ^ 9)
df <- transform(df, X10 = X ^ 10)
df <- transform(df, X11 = X ^ 11)
df <- transform(df, X12 = X ^ 12)
df <- transform(df, X13 = X ^ 13)
df <- transform(df, X14 = X ^ 14)
df <- transform(df, X15 = X ^ 15)
# fit to little polynomial
summary(lm(Y ~ X + X2 + X3, data = df))
# fit to big polynomial
summary(
lm(
Y ~
X + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11 + X12 + X13 + X14,
data = df)
)
# use "poly" to get orthogonal polynomials
summary(lm(Y ~ poly(X, degree = 14), data = df))
lm.out$coefficients
y <- sin(2 * pi * x) + rnorm(length(x), 0, 0.1)
x <- seq(0, 1, by = 0.01)
plt(x,y)
plot(x,y)
df <- transform(df, X2 = X ^ 2)
df <- transform(df, X3 = X ^ 3)
df <- transform(df, X4 = X ^ 4)
df <- transform(df, X5 = X ^ 5)
df <- transform(df, X6 = X ^ 6)
df <- transform(df, X7 = X ^ 7)
df <- transform(df, X8 = X ^ 8)
df <- transform(df, X9 = X ^ 9)
df <- transform(df, X10 = X ^ 10)
df <- transform(df, X11 = X ^ 11)
df <- transform(df, X12 = X ^ 12)
df <- transform(df, X13 = X ^ 13)
df <- transform(df, X14 = X ^ 14)
df <- transform(df, X15 = X ^ 15)
df
summary(lm(Y ~ X + X2 + X3, data = df))
summary(
lm(
Y ~
X + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11 + X12 + X13 + X14,
data = df)
)
summary(lm(Y ~ poly(X, degree = 14), data = df))
lm.out=lm(Y ~ poly(X, degree = 14), data = df)
lm.out
plot((predict(object = lm.out))
)
plot(predict(object = lm.out))
)
plot(predict(object = lm.out))
plot(predict(object = lm(Y ~ poly(X, degree = 14), data = df)))
plot(predict(object = lm(Y ~ poly(X, degree = 14), data = df),x=x))
plot(predict(object = lm(Y ~ poly(X, degree = 2), data = df),x=x))
plot(predict(object = lm(Y ~ poly(X, degree = 25), data = df),x=x))
plot(predict(object = lm(Y ~ poly(X, degree = 26), data = df),x=x))
plot(predict(object = lm(Y ~ poly(X, degree = 3), data = df),x=x))
plot(predict(object = lm(Y ~ poly(X, degree = 4), data = df),x=x))
plot(predict(object = lm(Y ~ poly(X, degree = 5), data = df),x=x))
plot(predict(object = lm(Y ~ poly(X, degree = 25), data = df),x=x))
library(glmnet)
set.seed(1010)
n=1000;p=100
nzc=trunc(p/10)
# define x as a bunch of random data
# NB: dim(x)=1000 x 100
x=matrix(rnorm(n*p),n,p)
beta=rnorm(nzc)
fx= x[,seq(nzc)] %*% beta
eps=rnorm(n)*5
y=fx+eps
cvob1=cv.glmnet(x,y)
plot(cvob1)
hist(eps)
summary(cvob1)
summary(cvob1$lambda.min)
plot(glmnet(x,y,alpha=0))
plot(glmnet(x,y))
plot(cvob1)
coef(cvob1)
cvob1=cv.glmnet(x,y,alpha=0)
plot(cvob2)
cvob2=cv.glmnet(x,y,alpha=0)
plot(cvob2)
coef(cvob2)
# what if L2?
plot(glmnet(x,y,alpha=0))
plot(glmnet(x,y))
ly=rbinom(n=length(px),prob=px,size=1)
coef(cvob2)
plot(glmnet(x,y))
cvob3a=cv.glmnet(x,ly,family="binomial",type.measure="auc")
plot(cvob3a)
cvob3a=cv.glmnet(x,ly,family="binomial",type.measure="auc")
plot(cvob3a)
px=exp(fx)
px=px/(1+px)
# make a "binary"/"dichotomous" random variable
ly=rbinom(n=length(px),prob=px,size=1)
cvob3a=cv.glmnet(x,ly,family="binomial",type.measure="auc")
plot(cvob3a)
plot(glmnet(x,y))
plot(cvob3a)
library(dplyr)
library(ggplot2)
library(scales)
library(reshape)
theme_set(theme_bw()) # a theme with a white background
users <- read.table(gzfile('users.tsv.gz'), header=T, sep="\t")
users <- read.table(gzfile('users.tsv.gz'), header=T, sep="\t")
setwd
setwd("~/github/msd2015/lectures/lecture_4")
users <- read.table(gzfile('users.tsv.gz'), header=T, sep="\t")
set.seed(42)
adults <- filter(users, age >= 20 & age <= 60)
num.train <- floor(nrow(adults)*0.5)
train.ndx <- sample(1:nrow(adults), num.train, replace=F)
adults.train <- adults[train.ndx, ]
adults.test <- adults[-train.ndx, ]
fit <- data.frame()
library(dplyr)
library(ggplot2)
library(scales)
library(reshape)
theme_set(theme_bw()) # a theme with a white background
#
# function to compute geometric mean
#
geom.mean <- function(x,dx=0.01) {
10^mean(log10(x+dx))-dx
}
# read user pageview data
users <- read.table(gzfile('users.tsv.gz'), header=T, sep="\t")
# 50/50 train/test split
set.seed(42)
adults <- filter(users, age >= 20 & age <= 60)
num.train <- floor(nrow(adults)*0.5)
train.ndx <- sample(1:nrow(adults), num.train, replace=F)
adults.train <- adults[train.ndx, ]
adults.test <- adults[-train.ndx, ]
fit <- data.frame()
for (k in 1:10) {
#form <- as.formula(sprintf('log10(daily.views+0.01) ~ gender*poly(age,%d)', k))
form <- as.formula(sprintf('daily.views ~ gender*poly(age,%d)', k))
model <- lm(form, data=adults.train)
#fit.train <- cor(10^predict(model, adults.train)-0.1, adults.train$daily.views)
#fit.test <- cor(10^predict(model, adults.test)-0.1, adults.test$daily.views)
fit.train <- cor(predict(model, adults.train), adults.train$daily.views)
fit.test <- cor(predict(model, adults.test), adults.test$daily.views)
#fit.train <- norm(predict(model, adults.train)- adults.train$daily.views,type="2")
#fit.test <- norm(predict(model, adults.test)- adults.test$daily.views,type="2")
fit <- rbind(fit, data.frame(k=k, train=fit.train, test=fit.test))
}
# plot train/test loss
plot.data <- melt(fit, id="k")
ggplot(data=plot.data, aes(x=k, y=value)) +
geom_line(aes(linetype=variable)) +
xlab('Degree') + ylab('R-squared') +
theme(legend.title=element_blank(), legend.position=c(0.9,0.8))
ggsave(filename='figures/cross_validation_polyfit_age.pdf', width=8, height=4)
# fit model at best value of k
best.test <- fit %>% filter(test == max(test))
best.test
form <- as.formula(sprintf('daily.views ~ gender*poly(age,%d)', best.test$k))
model <- lm(form, data=adults.train)
# compute mean / median / geometric mean daily pageviews by age / gender
views.by.age.gender <- filter(users, age <= 90) %>%
group_by(age, gender) %>%
summarize(mean.daily.views     =mean(     daily.views),
median.daily.views   =median(   daily.views),
geom.mean.daily.views=geom.mean(daily.views),
num.users            =length(   daily.views)
)
# create synthetic examples for both genders, all ages
# add predicted page views to synthetic examples
model.adults <- expand.grid(age=20:60, gender=factor(c('Male','Female')))
model.adults$daily.views <- predict(model, model.adults)
# plot modeled pageviews vs. actual
plot.data <- merge(model.adults, views.by.age.gender, by=c("age", "gender"))
ggplot(data=plot.data, aes(x=age, y=daily.views, colour=gender)) +
geom_line(aes(linetype=gender)) +
geom_point(aes(x=age, y=mean.daily.views, shape=gender)) +
xlab('Age') + ylab('Daily pageviews') +
theme(legend.title=element_blank(), legend.position=c(0.9,0.85))
ggsave(filename='figures/mean_daily_pageviews_by_age_and_gender.pdf', width=8, height=4)
